{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8np6u4s1rq0c"
   },
   "source": [
    "<table class=\"buttons\" align=\"center\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/dl-ub-summer-school/2019/blob/master/seminar4.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Google Colab дээр нээх</a>\n",
    "    </td>\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://github.com/dl-ub-summer-school/2019/blob/master/seminar4.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />GitHub дээр нээх</a>\n",
    "    </td>\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://sites.google.com/view/dlub/dl-ub-2019\"><img src=\"https://avatars0.githubusercontent.com/u/52651086?s=32&v=4\">Зуны сургалтын вебсайт</a>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eN8wqpjCdaoG"
   },
   "source": [
    "\n",
    "#Translation with a Sequence to Sequence Network and Attention\n",
    "*************************************************************\n",
    "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>` \\\n",
    "Эх сурвалж colab \\\n",
    "https://colab.research.google.com/drive/1wS4qI40tT0COGgSKo_oMas_4h6OLBjD2#scrollTo=eN8wqpjCdaoG&line=5&uniqifier=1 \\\n",
    "\n",
    "Энэхүү материалыг Sean Robertson -ийн эх кодыг монгол болон англи хэлэнд зориулан бэлтгэсэн ба семинарын үндсэн сэдэв зориулан зарим хэсгүүдэд нэмэлт тайлбар зүүн, зарим хэсгүүдийг нь дарсан болно.\n",
    "\n",
    "::\n",
    "\n",
    "    [KEY: > input, = target, < output]\n",
    "\n",
    "    > Тэд ЭЗЭНий тухай худал хэлж, “Энэ нь Тэр биш. Золгүй явдал бидэн дээр ирэхгүй. Бид өлсгөлөн, эсвэл илдийг үзэхгүй.\n",
    "    = They have belied the LORD, and said, It is not he; neither shall evil come upon us; neither shall we see sword nor famine:\n",
    "    < And they shall not shall the the the the the the the the the the LORD, and the the the the the of the the <EOS>\n",
    "\n",
    "    > Өшөө авах хилэн гарч ирэхээр, Би түүний цусыг далдлуулахгүйн тулд нүцгэн хадан дээр урсгасан”.\n",
    "    = That it might cause fury to come up to take vengeance; I have set her blood upon the top of a rock, that it should not be covered.\n",
    "    < And I will bring forth to the of the I the of the the the I the of the the the <EOS>\n",
    "    \n",
    "**Анхаарах зүйлс:**\n",
    "\n",
    "Эхлээд дараах үйлдлүүдийг дагаж хийгээд энэ нөтбүкийг өөрийн Драйвтаа хадгалж аваарай.\n",
    "\n",
    "1. Зүүн дээд буланд байгаа _File_ дээр дараад\n",
    "2. _Save copy in Drive_ дээр дарж өөрийн хувийг үүсгээд\n",
    "3. Үүсгэсэн Колаб нөтбүк дээрээ ажилла.\n",
    "4. Дараа нь энэ Колаб нөтбүкээ Драйв доторх Colab Notebooks гэдэг нэртэй, автоматаар үүсдэг хавтсан дотроос олж үзээрэй.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "33nbG7GkjrZl"
   },
   "source": [
    "**Хэрэгтэй сангуудаа суулгах нь**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20mgE2Kwdan_"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gr-4l3G1daoI"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rtuH6NhkO25T",
    "outputId": "21fc1f84-c245-4755-efdc-c1d12585c203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "e6qYMDSH6TO3",
    "outputId": "c74b3e82-dd0a-425e-dcf5-96cc9b8ef705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '2019'...\n",
      "remote: Enumerating objects: 58, done.\u001b[K\n",
      "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
      "remote: Total 58 (delta 27), reused 22 (delta 7), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (58/58), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone --recursive https://github.com/dl-ub-summer-school/2019.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMWcfAwTdaoL"
   },
   "source": [
    "Дата бэлтгэл\n",
    "==================\n",
    "NLP -ийн аливаа таскыг хийхэд юун түрүүнд өгөгдлөө машинд илэрхийлэхэд тохиромжтой хэлбэр рүү шилжүүлэх хэрэгтэй.\n",
    "Ийн шижүүлэхдээ data preprocessing гэх хэд хэдэн алхамтай үйлдлийг дамждаг. \n",
    "Семинарын цагтаа тааруулан бид тэдгээр шатуудын ихэнхийг алгасан цэвэрхэн датан дээр ажиллах болно.\n",
    "\n",
    "*  Parallel corpora format\n",
    "> Machine translation гэх NLP таскын датаг ийн нэрлэдэг. Семинартаа зориулан сонгож уг форматаар бэлдсэн дата - Библи\n",
    "*  Датаг python дээр унших\n",
    "> Датаны нэр - eng-mng.txt\n",
    "\n",
    "*Дата сонголтын тухай*:\n",
    "*(Шашны урсгалын судар тул орчуулгын хувьд харьцангуй алдаа багатай)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "licbEZgXypRv"
   },
   "source": [
    "**Word embedding**\n",
    "\n",
    "Word embedding хийх олон арга байдаг талаар эхний лекцэн дээр дурьдсан.\n",
    "\n",
    "Энэ удаад Embedding хийхэд хамгийн энгийн арга буюу нийт текстийг хоосон зайгаар нь салгаж үг бүрийг нэг токен гэж үзэцгээе. Үүний дараа токен бүрийг тодорхой урттай вектороор илэрхийлэнэ.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1MD2eT_WedDW"
   },
   "source": [
    "##Дата бэлтгэлийн функцууд"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доорхи класст ялгаатай токенуудыг багтаасан dictionary үүсгэж байна. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbyedrWbdaoQ"
   },
   "outputs": [],
   "source": [
    "# SOS - Start of sequence token\n",
    "# EOS - End of sequence token\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vFPAfeDdaoU"
   },
   "source": [
    "Гараас өгөх текстүүд нь Unicode форматтай байгаа ба дараах үйлдлүүдийг хийх функцууд.\n",
    "\n",
    "> 1. ASCII формат руу хөрвүүлэх.\n",
    "> 2. Нормалчлах буюу: \n",
    ">> 2.1.Том үсгүүдийг жижиг үсэг болгох (lowercase) \\\n",
    ">> 2.2. \" . \", \" ! \", \" ? \" тэмдэгтүүдийг солино.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYn4zDNCdaoU"
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdUDiwlaYkBd"
   },
   "source": [
    "Орчуулгын таскад бэлдсэн датаны мөр бүрийг pair (хосмог гэх) болгон бэлтгэх функц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZt8Wh1RdaoZ"
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Файлыг уншин мөр бүрт шилжүүлж байна.\n",
    "\n",
    "    \n",
    "    input_data='/content/2019/seminar4/%s-%s.txt'\n",
    "    lines = open(input_data % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    \n",
    "#     Өгөгдсөн дата файлыг мөр бүрийг python list хэлбэрт шилжүүлэн, python list-эд хадгалж байна. \n",
    "#     Ө.х.: листийг листэнд хадгалж байна.\n",
    "\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "#     Хоёр хэлийг бэлтгэгдсэн датанаас урвуу чиглэлд орчуулалт сургах тохиолдолд уг flag-ийг ашиглах.\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zGiR7PuNVIDc"
   },
   "source": [
    "Sequence нь өгөгдсөн MAX_LENGTH -ээс бага урттай байдаг sample -уудыг ялгаж авна.\n",
    "Өөрөөр хэлбэл:\n",
    "\n",
    "> MAX_LENGTH = 5 үед \\\n",
    "> **In the beginning God created the heaven and the earth.\t  Эхэнд Бурхан тэнгэр газрыг бүтээжээ.**\n",
    "> гэдэг өгүүлбэрүүд сургалтанд орохгүй.\n",
    "\n",
    "\n",
    "Энэ семинарын хувьд, нийт текст дээрээ дата анализ хийн sequence бүрийн токены тоог гарган дундажлан 25 гэж тогтсон. Тиймээс энэ хэмжээгээр явах юм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUkJdrBddaoe"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 25\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AtlDyTCuZVXr"
   },
   "source": [
    "##Дата бэлтгэлийн гол функц\n",
    "\n",
    "1.   Оролтын файлаа кодондоо уншиж мөр бүрийг нь орчуулгын хосмог болгоно.\n",
    "2.   Текстээ нормалчилана.\n",
    "3.    Өгүүлбэрийн хосмогуудаасаа үгийн жагсаалт гаргана.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "m-V2xUCSdaoi",
    "outputId": "ee35e7f9-f08f-4b1b-a229-a58dcd1c48b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 31103 sentence pairs\n",
      "Trimmed to 15283 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "mng 27640\n",
      "eng 15352\n",
      "Total words of source language mng 212607\n",
      "Total words of target language eng 265674\n",
      "['учир нь минии эцэг та нарын төлөө тулалдаж, өөриин амииг үл хаирлан та нарыг мидианы савраас аварсан билээ .', '(for my father fought for you, and adventured his life far, and delivered you out of the hand of midian:']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted unique words of\", input_lang.name, \"is\", input_lang.n_words)\n",
    "    print(\"Counted unique words of\", output_lang.name, \"is\", output_lang.n_words)\n",
    "    print(\"Total words of source language %s\" % input_lang.name, sum(list((input_lang.word2count).values())))\n",
    "    print(\"Total words of target language %s\" % output_lang.name, sum(list((output_lang.word2count).values())))\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'mng', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5DiTmsCAe5Lo"
   },
   "source": [
    "The Seq2Seq Model\n",
    "=================\n",
    "\n",
    "Recurrent Neural Network буюу RNN нь дараалал хэлбэртэй датан дээр ажилладаг. \\\n",
    "Seq2Seq буюу Sequence to Sequence модел нь encoder-decoder гэсэн хоёр RNN архитектурыг ашигладаг. Encoder нь оролт sequence-ийг тодорхой урттай вектор руу буулгахад, decoder нь уг буусан векторыг гаралт sequence руу хөрвүүлдэг. Энэхүү дундын векторын (цаашид дундын вектор гэх) үүрэг нь оролтын датаны **бүрэн мэдээллийг агуулан цааш дамжуулах**  ба моделийн давуу тал нь энгийн RNN -шиг оролт болон гаралтын хэмжээнүүд нь нэг нөгөөгөөсөө шууд хамааралгүй байна.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NqANY-duUPFA"
   },
   "source": [
    "Энкодер\n",
    "-----------\n",
    "\n",
    "Sequence-ийн токен бүрт тодорхой hidden_size урттай вектор гарах ба  **1 x hidden_size**   (1, 256) хэмжээтэй матриц байна гэж төсөөлж болно.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SvAsgQPdaoo"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "  \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0SDa10XaBGZ"
   },
   "source": [
    "Декодер\n",
    "-----------\n",
    "\n",
    "Энкодер -оос гарч ирсэн дундын векторыг орчуулах хэлний sequence рүү буулгана. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "viQKBpyZ8HAj"
   },
   "source": [
    "**Энгийн декодер** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2WoBnJN7r9B"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnXokAzSdbyk"
   },
   "source": [
    "**Attention Decoder**\n",
    "\n",
    "Attention mechanism нь дэкодэрийг алхам бүртээ энкодероос гарч буй векторуудын өөр өөр хэсгүүдэд төвлөрөх нөхцөлийг бүрдүүлдэг. Ингэхдээ\n",
    "\n",
    "\n",
    "> 1. *Attention weights* -үүдийг тооцон\n",
    "> 2. Энэхүү жинг энкодерын гаралтын вектороор үржүүлэнэ. Ингэснээр оролтын sequence-ийн тодорхой хэсгийн мэдээллийг агуулсан вектор гарах юм.\n",
    "\n",
    "\n",
    " *Attention weights* -үүдийг тооцоолохдоо декодерийн оролт болон hidden state -үүдийг нь оролтоор авсан feed-forward layer явуулана. Өгөгдөл текстүүд маань янз бүрийн урттай байдаг. Харин цаана явагдах тооцооллууд тогтмол хэмжээтэй байх хэрэгтэй тул sequence болон үгсийн жагсаалтыг гаргадаг.\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMpd7Bzndao4"
   },
   "outputs": [],
   "source": [
    "# Энд \"---\"-аар тухайн үйлдлийн гаралтуудын хэмжээг тавьлаа.\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "  \n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "      \n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size # given as 256\n",
    "        self.output_size = output_size # target_language_dict_size\n",
    "        self.dropout_p = dropout_p # given as 0.1\n",
    "        self.max_length = max_length # given as 25\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # ---1x1x256\n",
    "        embedded = self.embedding(input).view(1, 1, -1) \n",
    "        \n",
    "        # ---1x1x256\n",
    "        embedded = self.dropout(embedded) \n",
    "        \n",
    "        # --- 1x512 \n",
    "        concated=torch.cat((embedded[0], hidden[0]), 1)\n",
    "        \n",
    "        # --- 1x25\n",
    "        attention=self.attn(concated)\n",
    "        \n",
    "        # --- 1x25\n",
    "        attn_weights = F.softmax(attention, dim=1)\n",
    "        \n",
    "        # --- 1x1x25 \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), # --- 1x1x25\n",
    "                                 encoder_outputs.unsqueeze(0)) # --- 1x25x256\n",
    "        \n",
    "        # --- 1x512\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1) \n",
    "        \n",
    "        # --- 1x1x256\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        # --- 1x1x256\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # 1x1x256, 1x1x256\n",
    "        output, hidden = self.gru(output, hidden) \n",
    "        \n",
    "        #1x{target_language_dict_size}\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1) \n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSdPWoFeK_YH"
   },
   "source": [
    "Энд,  \"local attention\"-ий тухай ойлголтыг `Effective Approaches to Attention-based Neural Machine\n",
    "  Translation <https://arxiv.org/abs/1508.04025>` -ээс уншиж болно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwJKLguRLscm"
   },
   "source": [
    "Сургалтын датаг бэлтгэх\n",
    "-------------------------------\n",
    "Модел руу датаг оруулахдаа тэнсор хэлбэр рүү шилжүүлэнэ. Ингэхдээ дээр зарласан Lang class -аас индексээ аван дараах байдлаар үүсгэнэ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p48IxFy0dapA"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VkaJLPbQqTZ"
   },
   "source": [
    "Модел сургалт\n",
    "------------------\n",
    "Дараах алхамуудын хийнэ:\n",
    "\n",
    "-  Цагаа эхлүүлэх\n",
    "-  Optimizers and criterion-үүдэд анхны утга өгөх\n",
    "-  Сургалтын датагаа хосмог болгон бэлдэх\n",
    "-  Start empty losses array for plotting\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z_GhBNCYdapI"
   },
   "source": [
    "Сургалтын явцыг мэдэхэд зориулсан нэмэлт функц\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwvILvM0dapJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3HHEYIdowc4"
   },
   "source": [
    "Сургалтын нэг алхамыг хийж буй функц.\n",
    "\n",
    "Энд, нэг алхам гэдэг нь сургалтын бүх датагаа нэг удаа харахыг хэлнэ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UP-w8GVdapF"
   },
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad() \n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0) #column number\n",
    "    target_length = target_tensor.size(0) #column number\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    # initialize decoder\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "\n",
    "    for di in range(target_length):\n",
    "        \n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        \n",
    "        topv, topi = decoder_output.topk(1) #target word-ийг сонгож байгаа нь.\n",
    "        decoder_input = topi.squeeze().detach()  # дараагын токены индексыг сонгож байгаа нь.\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    loss.backward() # backpropagation тооцож байгаа нь\n",
    "\n",
    "    encoder_optimizer.step() #weight -үүдээ шинэчлэж байгаа нь\n",
    "    decoder_optimizer.step() #weight -үүдээ шинэчлэж байгаа нь\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkFGP21fdapL"
   },
   "source": [
    "Бид Stochastic Gradient Descent ашиглаж байгаа учраас датаны нэг sample бүр дээр лосс-оо тооцон weight-үүдээ шинэчлэнэ. Тиймээс дээр тодорхойлсон функцыг алхамыг хэдэн ч удаа хийсэн болно.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p3MtTyp1dapN"
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss() #negative log likelihood loss\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZn6HuXUdapU"
   },
   "source": [
    "Графикаар үзэх\n",
    "----------------\n",
    "\n",
    "Лoss -ийн утгуудыг хадгалж аван ``plot_losses``, үүнийгээ харах функцы\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5U13hQ9ZdapV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JrdCCJAudapd"
   },
   "source": [
    "##Модел шалгалт\n",
    "\n",
    "\n",
    "Модел сургалттай адил үйл явцтай авч датаны хувьд орчуулах хэлэн дээрхи дата нь орно. Өөрөөр хэлбэл, тухайн нэг өгүүлбэр ороход декодер орчуулан үг бүрээр нь таамаглал хийн гаргах болно.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ejc3X--mdaph"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7pSi2KRdaps"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iuHIgG8Sdap0"
   },
   "source": [
    "Сургалтыг эхлүүлэх ба сургаснаа шалгах\n",
    "==================================\n",
    "\n",
    "Hidden node -ийн утгыг гараас өгөн сургалтыг эхлүүлж болно.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "BezA7Hwidap1",
    "outputId": "930749d1-bf7e-4542-a029-c7eb6c1c1143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 35s (- 10m 20s) (4000 20%) 4.8725\n",
      "5m 11s (- 7m 47s) (8000 40%) 4.8061\n",
      "7m 55s (- 5m 16s) (12000 60%) 4.7652\n",
      "10m 40s (- 2m 40s) (16000 80%) 4.7310\n",
      "13m 24s (- 0m 0s) (20000 100%) 4.6628\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 20000, print_every=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "7bcI4BjXdap4",
    "outputId": "84613381-0645-4caa-812b-963c362d437d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> нэг үеиинхэн таны үилсииг нөгөө үеиинхэнд магтаж, таны хүчирхэг үилдлүүдииг тунхаглана .\n",
      "= one generation shall praise thy works to another, and shall declare thy mighty acts .\n",
      "< and the the one the the and the and the the . . <EOS>\n",
      "\n",
      "> шударга хиигээд зөвииг үилдэх нь эзэнд өргөлөөс ч илүү таалагддаг .\n",
      "= to do justice and judgment is more acceptable to the lord than sacrifice .\n",
      "< the the the the the the the the the the the the the the <EOS>\n",
      "\n",
      "> эзэн есүсииг амилуулсан нэгэн биднииг ч бас есүстэи хамт амилуулж, биднииг та нарын хамт өөриинхөө өмнө аваачна гэдгииг бид мэддэг .\n",
      "= knowing that he which raised up the lord jesus shall raise up us also by jesus, and shall present us with you .\n",
      "< and the lord the the the the the the the the the the the the the the . the <EOS>\n",
      "\n",
      "> паул ч, апол ч, кеф ч, ертөнц ч, амь хиигээд үхэл ч, одоо хиигээд ирээдүи ч бүгд та нарынх аж .\n",
      "= whether paul, or apollos, or cephas, or the world, or life, or death, or things present, or things to come; all are your's;\n",
      "< for the the of the the the the but the but the the the the . <EOS>\n",
      "\n",
      "> “хаана баина, өвөг дээдэс чинь ? эш үзүүлэгчид мөнх амьдардаг уу ?\n",
      "= your fathers, where are they ? and the prophets, do they live for ever ?\n",
      "< the thou the the the the the ? the ? ? the ? <EOS>\n",
      "\n",
      "> энэ нөхцөлд үхэх хүмүүс аравны нэгииг авдаг юм бол, тэр нөхцөлд амьд гэж гэрчлэгдсэн нь авдаг баина .\n",
      "= and here men that die receive tithes; but there he receiveth them, of whom it is witnessed that he liveth .\n",
      "< but he is the the the the the the the . the . <EOS>\n",
      "\n",
      "> христ биднииг эрх чөлөөтэи болгохын тулд чөлөөлсөн юм . иимд бат зогс, дахиж боолчлолын буулганд бүү орогтун .\n",
      "= stand fast therefore in the liberty wherewith christ hath made us free, and be not entangled again with the yoke of bondage .\n",
      "< but not not is the but but but is the of . <EOS>\n",
      "\n",
      "> түрүү цухуиж үр тариа боловсроход, зэрлэг өвс ч бас илт болов .\n",
      "= but when the blade was sprung up, and brought forth fruit, then appeared the tares also .\n",
      "< the the the the the the the the the and the the the the the . <EOS>\n",
      "\n",
      "> шеломитын хөвгүүдээс иосифиагиин хүү болон түүнтэи хамт зуун жаран эрчүүд,\n",
      "= and of the sons of shelomith; the son of josiphiah, and with him an hundred and threescore males .\n",
      "< and the sons of of the of the the sons of and and and and and <EOS>\n",
      "\n",
      "> харин би сонссон боловч оилгож чадсангүи . тиимээс би -эзэн минь, энэ бүх явдлын үр дүн юу болох вэ ? гэж асуув .\n",
      "= and i heard, but i understood not: then said i, o my lord, what shall be the end of these things ?\n",
      "< but i is i i but but but but i but ? <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qiutt7nCdap7"
   },
   "source": [
    "Attention-г харах\n",
    "---------------------\n",
    "\n",
    "Өгүүлбэрийн хаана attend хийж байгааг харах функц.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJQMxTURdap7"
   },
   "outputs": [],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"эзэний тухай худал цуу яриа гарчээ\") \n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhRvcWiLdap9"
   },
   "source": [
    "For a better viewing experience we will do the extra work of adding axes\n",
    "and labels:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAECLNAadap-"
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"эзэний тухай худал цуу яриа гарчээ\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qgneIsNrqaSi"
   },
   "source": [
    "## Нэмэлт санал болгох материалууд"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcCXFHoCk3pW"
   },
   "source": [
    "-`Sequence to sequence network <http://arxiv.org/abs/1409.3215>`__ \n",
    "- `Attention mechanism <https://arxiv.org/abs/1409.0473>`__ \\\n",
    "-  `Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation <http://arxiv.org/abs/1406.1078>`__\n",
    "-  `Sequence to Sequence Learning with Neural\n",
    "   Networks <http://arxiv.org/abs/1409.3215>`__\n",
    "-  `Neural Machine Translation by Jointly Learning to Align and\n",
    "   Translate <https://arxiv.org/abs/1409.0473>`__\n",
    "-  `A Neural Conversational Model <http://arxiv.org/abs/1506.05869>`\n",
    "- `Sequence to Sequence network <http://arxiv.org/abs/1409.3215>`  \n",
    "- `Encoder Decoder network <https://arxiv.org/pdf/1406.1078v3.pdf>`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seminar4.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
