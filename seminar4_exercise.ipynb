{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "seminar4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8np6u4s1rq0c",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"buttons\" align=\"center\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1wS4qI40tT0COGgSKo_oMas_4h6OLBjD2\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Google Colab дээр нээх</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/dl-ub-summer-school/2019/blob/master/seminar4.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />GitHub дээр нээх</a>\n",
        "  </td>\n",
        "  <td>\n",
        "       <a target=\"_blank\" href=\"https://sites.google.com/view/dlub/dl-ub-2019\"><img src=\"https://avatars0.githubusercontent.com/u/52651086?s=32&v=4\">Зуны сургалтын вебсайт</a>\n",
        "   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN8wqpjCdaoG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Translation with a Sequence to Sequence Network and Attention\n",
        "*************************************************************\n",
        "\n",
        "\n",
        "Энэхүү материалыг Sean Robertson -ийн эх кодыг монгол болон англи хэлэнд зориулан бэлтгэсэн ба семинарын үндсэн сэдэв зориулан зарим хэсгүүдэд нэмэлт тайлбар зүүн, зарим хэсгүүдийг нь дарсан болно.\n",
        "\n",
        "::\n",
        "\n",
        "    [KEY: > input, = target, < output]\n",
        "\n",
        "    > Тэд ЭЗЭНий тухай худал хэлж, “Энэ нь Тэр биш. Золгүй явдал бидэн дээр ирэхгүй. Бид өлсгөлөн, эсвэл илдийг үзэхгүй.\n",
        "    = They have belied the LORD, and said, It is not he; neither shall evil come upon us; neither shall we see sword nor famine:\n",
        "    < And they shall not shall the the the the the the the the the the LORD, and the the the the the of the the <EOS>\n",
        "\n",
        "    > Өшөө авах хилэн гарч ирэхээр, Би түүний цусыг далдлуулахгүйн тулд нүцгэн хадан дээр урсгасан”.\n",
        "    = That it might cause fury to come up to take vengeance; I have set her blood upon the top of a rock, that it should not be covered.\n",
        "    < And I will bring forth to the of the I the of the the the I the of the the the <EOS>\n",
        "    \n",
        "**Анхаарах зүйлс:**\n",
        "\n",
        "Эхлээд дараах үйлдлүүдийг дагаж хийгээд энэ нөтбүкийг өөрийн Драйвтаа хадгалж аваарай.\n",
        "\n",
        "1. Зүүн дээд буланд байгаа _File_ дээр дараад\n",
        "2. _Save copy in Drive_ дээр дарж өөрийн хувийг үүсгээд\n",
        "3. Үүсгэсэн Колаб нөтбүк дээрээ ажилла.\n",
        "4. Дараа нь энэ Колаб нөтбүкээ Драйв доторх Colab Notebooks гэдэг нэртэй, автоматаар үүсдэг хавтсан дотроос олж үзээрэй.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33nbG7GkjrZl",
        "colab_type": "text"
      },
      "source": [
        "**Хэрэгтэй сангуудаа суулгах нь**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20mgE2Kwdan_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr-4l3G1daoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtuH6NhkO25T",
        "colab_type": "code",
        "outputId": "76df3fbe-1882-4feb-c3e0-2c4337217327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6qYMDSH6TO3",
        "colab_type": "code",
        "outputId": "e8fa0cdb-ae5d-4d6f-b565-a23a44dad3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone --recursive https://github.com/dl-ub-summer-school/2019.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path '2019' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMWcfAwTdaoL",
        "colab_type": "text"
      },
      "source": [
        "Дата бэлтгэл\n",
        "==================\n",
        "NLP -ийн аливаа таскыг хийхэд юун түрүүнд өгөгдлөө илэрхийлэх хэрэгтэй.\n",
        "Ийн илэрхийлэхдээ data preprocessing гэх хэд хэдэн алхамтай шатыг дамждаг. \n",
        "Семинарын цагтаа тааруулан бид тэдгээр шатуудыг алгасан цэвэрхэн датан дээр ажиллах болно.\n",
        "\n",
        "1.   Parallel corpora format\n",
        "> Семинарын хувьд сонгосон дата - Библи\n",
        "2.   Датаг python дээр унших\n",
        ">Датаны нэр - eng-mng.txt\n",
        "\n",
        "*Семинарын хувьд сонгосон датаны тухай*:\n",
        "*(Шашны урсгалын судар тул орчуулгын хувьд харьцангуй алдаа багатай)*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "licbEZgXypRv",
        "colab_type": "text"
      },
      "source": [
        "**Word embedding**\n",
        "\n",
        "Word embedding хийх олон арга байдаг талаар эхний лекцэн дээр дурьдсан.\n",
        "\n",
        "Энэ удаад Embedding хийхэд хамгийн энгийн арга буюу нийт текстийг хоосон зайгаар нь салгаж үг бүрийг нэг токен гэж үзэцгээе. Үүний дараа токен бүрийг тодорхой урттай вектороор илэрхийлэнэ.\n",
        "Мөн Sequence-тэй ажиллаж байгаа үед тухайн үг бүрийн байрлалын мэдээлэл өгүүлбэр зүйн хувьд чухал байдаг тул уг мэдээллийг авах зорилгоор үг бүрт индекс оноодог. Энд тухайн үг sequence-ийнх нь хувьд хэд дэх токен гэдгээр индэкслэж байна. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MD2eT_WedDW",
        "colab_type": "text"
      },
      "source": [
        "##Дата бэлтгэлийн функцууд"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbyedrWbdaoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Үг бүртээ давтагдахгүй утгатай индекс оноож өгч байна.\n",
        "# SOS - Start of sequence token\n",
        "# EOS - End of sequence token\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vFPAfeDdaoU",
        "colab_type": "text"
      },
      "source": [
        "Гараас өгөх текстүүд нь Unicode форматтай байгаа ба дараах үйлдлүүдийг хийх функцууд.\n",
        "\n",
        "> 1. ASCII формат руу хөрвүүлэх.\n",
        "> 2. Нормалчлах буюу: \n",
        ">> 2.1.Том үсгүүдийг жижиг үсэг болгох (lowercase) \\\n",
        ">> 2.2. \" . \", \" ! \", \" ? \" тэмдэгтүүдийг солино.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYn4zDNCdaoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdUDiwlaYkBd",
        "colab_type": "text"
      },
      "source": [
        "Орчуулгын таскад бэлдсэн датаны мөр бүрийг pair (хосмог гэх) болгон бэлтгэх функц."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZt8Wh1RdaoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Файлыг уншин мөр бүрт шилжүүлж байна.\n",
        "\n",
        "    \n",
        "    input_data='/content/2019/%s-%s.txt'\n",
        "    lines = open(input_data % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    \n",
        "#     Өгөгдсөн дата файлыг мөр бүрийг python list хэлбэрт шилжүүлэн, python list-эд хадгалж байна. \n",
        "#     Ө.х.: листийг листэнд хадгалж байна.\n",
        "\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    \n",
        "#     Хоёр хэлийг бэлтгэгдсэн датанаас урвуу чиглэлд орчуулалт сургах тохиолдолд уг flag-ийг ашиглах.\n",
        "    \n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGiR7PuNVIDc",
        "colab_type": "text"
      },
      "source": [
        "Sequence нь өгөгдсөн MAX_LENGTH -ээс бага урттай байдаг sample -уудыг ялгаж авна.\n",
        "Өөрөөр хэлбэл:\n",
        "\n",
        "> MAX_LENGTH = 5 үед \\\n",
        "> **In the beginning God created the heaven and the earth.\t  Эхэнд Бурхан тэнгэр газрыг бүтээжээ.**\n",
        "> гэдэг өгүүлбэрүүд сургалтанд орохгүй.\n",
        "\n",
        "\n",
        "Энэ семинарын хувьд, нийт текст дээрээ дата анализ хийн sequence бүрийн токены тоог гарган дундажлан 25 гэж тогтсон. Тиймээс энэ хэмжээгээр явах юм."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkJdrBddaoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 25\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtlDyTCuZVXr",
        "colab_type": "text"
      },
      "source": [
        "##Дата бэлтгэлийн гол функц\n",
        "\n",
        "1.   Оролтын файлаа кодондоо уншиж мөр бүрийг нь орчуулгын хосмог болгоно.\n",
        "2.   Текстээ нормалчилана.\n",
        "3.    Өгүүлбэрийн хосмогуудаасаа үгийн жагсаалт гаргана.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-V2xUCSdaoi",
        "colab_type": "code",
        "outputId": "3419cd96-feca-4c0a-d7ab-21e75312f7ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    print(\"Total words of source language %s\" % input_lang.name, sum(list((input_lang.word2count).values())))\n",
        "    print(\"Total words of target language %s\" % output_lang.name, sum(list((output_lang.word2count).values())))\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'mng', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 31103 sentence pairs\n",
            "Trimmed to 15283 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "mng 27640\n",
            "eng 15352\n",
            "Total words of source language mng 212607\n",
            "Total words of target language eng 265674\n",
            "['тэгээд тэд тус тусынхаа уутыг газарт яаран буулгаж, хүн бүр уутаа нээсэнд', 'then they speedily took down every man his sack to the ground, and opened every man his sack .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DiTmsCAe5Lo",
        "colab_type": "text"
      },
      "source": [
        "The Seq2Seq Model\n",
        "=================\n",
        "\n",
        "Recurrent Neural Network буюу RNN нь дараалал хэлбэртэй датан дээр ажилладаг. \\\n",
        "Seq2Seq буюу Sequence to Sequence модел нь encoder-decoder гэсэн хоёр RNN архитектурыг ашигладаг. Encoder нь оролт sequence-ийг тодорхой урттай вектор руу буулгахад, decoder нь уг буусан векторыг гаралт sequence руу хөрвүүлдэг. Энэхүү дундын векторын (цаашид дундын вектор гэх) үүрэг нь оролтын датаны **бүрэн мэдээллийг агуулан цааш дамжуулах**  ба моделийн давуу тал нь энгийн RNN -шиг оролт болон гаралтын хэмжээнүүд нь нэг нөгөөгөөсөө шууд хамааралгүй байна.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqANY-duUPFA",
        "colab_type": "text"
      },
      "source": [
        "Энкодер\n",
        "-----------\n",
        "\n",
        "Sequence-ийн токен бүрт тодорхой hidden_size урттай вектор гарах ба  **1 x hidden_size**   (1, 256) хэмжээтэй матриц байна гэж төсөөлж болно.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SvAsgQPdaoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  \n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0SDa10XaBGZ",
        "colab_type": "text"
      },
      "source": [
        "Декодер\n",
        "-----------\n",
        "\n",
        "Энкодер -оос гарч ирсэн дундын векторыг орчуулах хэлний sequence рүү буулгана. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viQKBpyZ8HAj",
        "colab_type": "text"
      },
      "source": [
        "**Дасгал:** \\\n",
        "Энгийн Decoder -ийн кодыг бичнэ үү. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2WoBnJN7r9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        ...\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnXokAzSdbyk",
        "colab_type": "text"
      },
      "source": [
        "**Attention Decoder**\n",
        "\n",
        "Attention mechanism нь дэкодэрийг алхам бүртээ энкодероос гарч буй векторуудын өөр өөр хэсгүүдэд төвлөрөх нөхцөлийг бүрдүүлдэг. Ингэхдээ\n",
        "\n",
        "\n",
        "> 1. *Attention weights* -үүдийг тооцон\n",
        "> 2. Энэхүү жинг энкодерын гаралтын вектороор үржүүлэнэ. Ингэснээр оролтын sequence-ийн тодорхой хэсгийн мэдээллийг агуулсан вектор гарах юм.\n",
        "\n",
        "\n",
        " *Attention weights* -үүдийг тооцоолохдоо декодерийн оролт болон hidden state -үүдийг нь оролтоор авсан feed-forward layer явуулана. Өгөгдөл текстүүд маань янз бүрийн урттай байдаг. Харин цаана явагдах тооцооллууд тогтмол хэмжээтэй байх хэрэгтэй тул sequence болон үгсийн жагсаалтыг гаргадаг.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMpd7Bzndao4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "  \n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "      \n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size #256\n",
        "        self.output_size = output_size #output_vocab_size\n",
        "        self.dropout_p = dropout_p #given=0.1\n",
        "        self.max_length = max_length # given=25\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1) # (1, 1, 256)\n",
        "        embedded = self.dropout(embedded) # (1, 1, 256)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        # torch.cat((embedded[0], hidden[0]), (1, 512)\n",
        "        # attn(torch.cat((embedded[0], hidden[0]), 1)), (1, 25)\n",
        "        # attn_weights, (1, 25) , sum==1\n",
        "        \n",
        "        #torch.cat: concates vectors, (1, 1, 256)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), # (1, 1, 25)\n",
        "                                 encoder_outputs.unsqueeze(0)) # (1, 25, 256)\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1) # (1, 512)\n",
        "        output = self.attn_combine(output).unsqueeze(0) # (1, 1, 256)\n",
        "\n",
        "        output = F.relu(output) # (1, 1, 256)\n",
        "        output, hidden = self.gru(output, hidden) #(1, 1, 256), (1, 1, 256)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1) # (1, output_vocab_size)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSdPWoFeK_YH",
        "colab_type": "text"
      },
      "source": [
        "Энд,  \"local attention\"-ий тухай ойлголтыг `Effective Approaches to Attention-based Neural Machine\n",
        "  Translation <https://arxiv.org/abs/1508.04025>` -ээс уншиж болно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwJKLguRLscm",
        "colab_type": "text"
      },
      "source": [
        "Сургалтын датаг бэлтгэх\n",
        "-------------------------------\n",
        "Модел руу датаг оруулахдаа тэнсор хэлбэр рүү шилжүүлэнэ. Ингэхдээ дээр зарласан Lang class -аас индексээ аван дараах байдлаар үүсгэнэ.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p48IxFy0dapA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VkaJLPbQqTZ",
        "colab_type": "text"
      },
      "source": [
        "Модел сургалт\n",
        "------------------\n",
        "Дараах алхамуудын хийнэ:\n",
        "\n",
        "-  Цагаа эхлүүлэх\n",
        "-  Optimizers and criterion-үүдэд анхны утга өгөх\n",
        "-  Сургалтын датагаа хосмог болгон бэлдэх\n",
        "-  Start empty losses array for plotting\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_GhBNCYdapI",
        "colab_type": "text"
      },
      "source": [
        "Сургалтын явцыг мэдэхэд зориулсан нэмэлт функц\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwvILvM0dapJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3HHEYIdowc4",
        "colab_type": "text"
      },
      "source": [
        "Сургалтын нэг алхамыг хийж буй функц.\n",
        "\n",
        "Энд, нэг алхам гэдэг нь сургалтын бүх датагаа нэг удаа харахыг хэлнэ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UP-w8GVdapF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad() # Clears the gradients of all optimized torch.Tensor s.\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0) #column number\n",
        "    target_length = target_tensor.size(0) #column number\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "        \n",
        "    # initialize decoder\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "            decoder_input, decoder_hidden, encoder_outputs)\n",
        "        topv, topi = decoder_output.topk(1) #target word-ийг сонгож байгаа нь.\n",
        "        decoder_input = topi.squeeze().detach()  # дараагын токены индексыг сонгож байгаа нь.\n",
        "\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        if decoder_input.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    loss.backward() # backpropagation тооцож байгаа нь\n",
        "\n",
        "    encoder_optimizer.step() #weight -үүдээ шинэчлэж байгаа нь\n",
        "    decoder_optimizer.step() #weight -үүдээ шинэчлэж байгаа нь\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkFGP21fdapL",
        "colab_type": "text"
      },
      "source": [
        "Бид Stochastic Gradient Descent ашиглаж байгаа учраас датаны нэг sample бүр дээр лосс-оо тооцон weight-үүдээ шинэчлэнэ. Тиймээс дээр тодорхойлсон функцыг алхамыг хэдэн ч удаа хийсэн болно.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3MtTyp1dapN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss() #negative log likelihood loss\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZn6HuXUdapU",
        "colab_type": "text"
      },
      "source": [
        "Графикаар үзэх\n",
        "----------------\n",
        "\n",
        "Лoss -ийн утгуудыг хадгалж аван ``plot_losses``, үүнийгээ харах функцы\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U13hQ9ZdapV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrdCCJAudapd",
        "colab_type": "text"
      },
      "source": [
        "##Модел шалгалт\n",
        "\n",
        "\n",
        "Модел сургалттай адил үйл явцтай авч датаны хувьд орчуулах хэлэн дээрхи дата нь орно. Өөрөөр хэлбэл, тухайн нэг өгүүлбэр ороход декодер орчуулан үг бүрээр нь таамаглал хийн гаргах болно.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejc3X--mdaph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7pSi2KRdaps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuHIgG8Sdap0",
        "colab_type": "text"
      },
      "source": [
        "Сургалтыг эхлүүлэх ба сургаснаа шалгах\n",
        "==================================\n",
        "\n",
        "Hidden node -ийн утгыг гараас өгөн сургалтыг эхлүүлж болно.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BezA7Hwidap1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 150000, print_every=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bcI4BjXdap4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qiutt7nCdap7",
        "colab_type": "text"
      },
      "source": [
        "Attention-г харах\n",
        "---------------------\n",
        "\n",
        "Өгүүлбэрийн хаана attend хийж байгааг харах функц.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJQMxTURdap7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"Эзэний тухай худал цуу яриа гарчээ.\") \n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhRvcWiLdap9",
        "colab_type": "text"
      },
      "source": [
        "For a better viewing experience we will do the extra work of adding axes\n",
        "and labels:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAECLNAadap-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"Эзэний тухай худал цуу яриа гарчээ.\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgneIsNrqaSi",
        "colab_type": "text"
      },
      "source": [
        "## Нэмэлт санал болгох материалууд"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcCXFHoCk3pW",
        "colab_type": "text"
      },
      "source": [
        "-`Sequence to sequence network <http://arxiv.org/abs/1409.3215>`__ \n",
        "- `Attention mechanism <https://arxiv.org/abs/1409.0473>`__ \\\n",
        "-  `Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation <http://arxiv.org/abs/1406.1078>`__\n",
        "-  `Sequence to Sequence Learning with Neural\n",
        "   Networks <http://arxiv.org/abs/1409.3215>`__\n",
        "-  `Neural Machine Translation by Jointly Learning to Align and\n",
        "   Translate <https://arxiv.org/abs/1409.0473>`__\n",
        "-  `A Neural Conversational Model <http://arxiv.org/abs/1506.05869>`\n",
        "- `Sequence to Sequence network <http://arxiv.org/abs/1409.3215>`  \n",
        "- `Encoder Decoder network <https://arxiv.org/pdf/1406.1078v3.pdf>`"
      ]
    }
  ]
}